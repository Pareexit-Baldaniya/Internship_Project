{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1, Task 1: Comparison of Memory-Based and Generator-Based Data Loading\n",
    "\n",
    "**Objective:** To understand and compare two primary methods of loading data: loading the entire dataset into memory versus using a data generator that loads data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install tensorflow tensorflow-datasets numpy matplotlib memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "First, let's import the libraries and load a sample of the EuroSAT dataset. We'll use `tensorflow_datasets` for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# Load the EuroSAT dataset metadata\n",
    "ds, ds_info = tfds.load('eurosat/rgb', with_info=True, as_supervised=True)\n",
    "train_ds = ds['train']\n",
    "\n",
    "print(f\"Total number of images in the dataset: {ds_info.splits['train'].num_examples}\")\n",
    "print(f\"Image shape: {ds_info.features['image'].shape}\")\n",
    "print(f\"Number of classes: {ds_info.features['label'].num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Memory-Based Data Loading\n",
    "\n",
    "Here, we load the entire dataset into RAM. This is feasible for small datasets but quickly becomes a bottleneck for large datasets, as it can exhaust the available system memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_into_memory():\n",
    "    \"\"\"Loads the entire EuroSAT dataset into numpy arrays in memory.\"\"\"\n",
    "    # Convert the tf.data.Dataset to a list of numpy arrays\n",
    "    images, labels = tfds.as_numpy(train_ds)\n",
    "    print(f\"Loaded {len(images)} images and {len(labels)} labels into memory.\")\n",
    "    print(f\"Images array shape: {images.shape}\")\n",
    "    print(f\"Labels array shape: {labels.shape}\")\n",
    "    return images, labels\n",
    "\n",
    "print(\"Measuring memory usage for memory-based loading...\")\n",
    "# The `memory_usage` function runs the target function and records its memory footprint.\n",
    "# The `max_usage=True` returns the peak memory usage during the function's execution.\n",
    "mem_based_peak_mem = memory_usage(load_into_memory, max_usage=True)\n",
    "\n",
    "print(f\"\\nPeak memory usage for memory-based loading: {mem_based_peak_mem:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Generator-Based Data Loading\n",
    "\n",
    "A generator is an iterable that yields data one batch at a time. It only loads the data for the current batch into memory, making it highly memory-efficient. TensorFlow's `tf.data.Dataset` API is a powerful, generator-based system for building efficient input pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_based_loading():\n",
    "    \"\"\"Simulates iterating through the dataset using a generator approach.\"\"\"\n",
    "    batch_size = 32\n",
    "    # The tf.data.Dataset object is already a generator.\n",
    "    # We just configure it with a batch size.\n",
    "    batched_ds = train_ds.batch(batch_size)\n",
    "    \n",
    "    print(f\"Processing dataset with a batch size of {batch_size}...\")\n",
    "    num_batches = 0\n",
    "    for images, labels in batched_ds:\n",
    "        # In a real training loop, you would perform an operation here.\n",
    "        # For this demo, we'll just simulate work with a small delay.\n",
    "        time.sleep(0.01)\n",
    "        num_batches += 1\n",
    "    \n",
    "    print(f\"Successfully processed {num_batches} batches.\")\n",
    "\n",
    "print(\"\\nMeasuring memory usage for generator-based loading...\")\n",
    "gen_based_peak_mem = memory_usage(generator_based_loading, max_usage=True)\n",
    "\n",
    "print(f\"\\nPeak memory usage for generator-based loading: {gen_based_peak_mem:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison and Conclusion\n",
    "\n",
    "Let's visualize the difference in peak memory consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['Memory-Based', 'Generator-Based']\n",
    "memory_values = [mem_based_peak_mem, gen_based_peak_mem]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(methods, memory_values, color=['orangered', 'dodgerblue'])\n",
    "plt.ylabel('Peak Memory Usage (MiB)')\n",
    "plt.title('Memory Usage Comparison: Memory-Based vs. Generator-Based Loading')\n",
    "plt.bar_label(bars, fmt='%.2f MiB')\n",
    "plt.show()\n",
    "\n",
    "print(\"Conclusion:\")\n",
    "print(\"- **Memory-Based Loading:** Consumes a large amount of RAM because the entire dataset is loaded at once. This approach is not scalable and will fail for datasets larger than the available RAM.\")\n",
    "print(\"- **Generator-Based Loading:** Exhibits significantly lower and constant memory usage. It only holds a small batch of data in memory at any given time, making it the standard and most efficient method for deep learning, especially with large datasets.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
